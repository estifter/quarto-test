{
  "hash": "41ae0370505294b2a7aa042df75988c1",
  "result": {
    "markdown": "---\ntitle: Lecture 23 - Additive White Gaussian Noise\n---\n\n## Summary\n\nIn this lecture, we will develop the mathematics required to model thermal noise, and certain other sources of intereference, as additive white Gaussian noise (AWGN).\n\n## Motivation in Course Context\n\nAll of the work we have done on our receiver to this point can be distilled into the equivalent circuit model shown in the figure below.\n\n![01](images/Lec23-01.png)\n\nHere $s(t)$ is the received signal voltage affected by the receiver circuit, $R_{eq}$ is the equivalent output impedance of the receiver circuit (often $50\\ \\Omega$), and $w_{eq}(t)$ is the equivalent output noise voltage source of the recevier circuit. The ADC is setup to measure the voltage across a load resistance $R_l$, which typically satisfies $R_l\\simeq 1\\ \\mathrm{M}\\Omega$.\n\nFrom the linearity of the equivalent circuit, the effects of the received signal voltage and equivalent noise voltage are *additive* across the load resistance. So the sampled output will be of the form\n\n$$\n  y[n] = \\frac{R_l}{R_l+R_{eq}} \\left( s[n] + w_e[n] \\right) \\simeq \\left( s[n] + w_e[n] \\right)\n$$\n\nassuming $R_{eq} \\ll R_l$.\n\n## Outline\n\n* Random Variables and Vectors Review\n\n* Gaussian Random Variables and Vectors\n\n* Simulation of AWGN Processes\n\n## Random Variables and Vectors\n\n### Random Variable\n\nA *random variable* $X(\\omega)$ is a mapping from the sample space $\\Omega$ to\nthe real numbers, i.e., $X : \\Omega \\rightarrow \\mathbb{R}$.\n\nNotes\n* Cumulative distribution function (CDF) $F_{X}(x)=\\mathbb{P}[X\\leq x]$\n* Probability density function (PDF) $f_{X}(x)=\\frac{d}{dx}F_{X}(x)$\n* Mean $\\mu_{X}=\\mathrm{E}[X]=\\int_{-\\infty}^{+\\infty}xf_{X}(x)dx$\n* Variance $\\sigma_{X}^{2}=\\mathrm{E}[|X-\\mathrm{E}[X]|^{2}]=\\mathrm{E}[|X|^{2}]-|\\mu_{X}|^{2}$\n\n### Pairs and Vectors of Random Variables\n\nA pair of variables $X$ and $Y$ are characterized as follows:\n\n* Joint CDF $F_{X,Y}(x,y):=\\Pr[X\\leq x,Y\\leq y]$\n* Joint PDF $f_{X,Y}(x,y)=\\frac{\\partial}{\\partial x}\\frac{\\partial}{\\partial y}P_{X,Y}(x,y)$\n* Marginal PDF $f_{X}(x)=\\int_{-\\infty}^{+\\infty}f_{X,Y}(x,y)dy$\n* Conditional PDF $f_{X|Y}(x|y)=\\frac{f_{X,Y}(x,y)}{f_{Y}(y)}$\n* Independence $f_{X|Y}(x|y)=f_{X}(x)$ for all $x,y$\n* Covariance $\\sigma_{X,Y}^{2}:=\\mathrm{E}[(X-\\mathrm{E}[X])(Y-\\mathrm{E}[Y])^{*}]$\n* Uncorrelated $\\sigma_{X,Y}^{2}=0$\n* Independent implies uncorrelated, but not necessarily vice versa\n\nA collection of random variables $X_1,X_2,\\ldots,X_n$ can be collected into a random vector\n\n$$\n  \\mathbf{X} = [\\begin{array}{cccc}\nX_{1} & X_{2} & \\cdots & X_{n}\\end{array}]^{\\intercal}\n$$\n\nand characterized as follows:\n\n* Joint CDF $F_{\\mathbf{X}}(\\mathbf{x})$ or PDF $f_{\\mathbf{X}}(\\mathbf{x})$\n* Mean vector\n\n$$\n  \\boldsymbol{\\mu}_{\\mathbf{X}}=\\mathrm{E}[\\mathbf{X}]=[\\begin{array}{cccc}\n\\mu_{X_{1}} & \\mu_{X_{2}} & \\cdots & \\mu_{X_{n}}\\end{array}]^{\\intercal}\n$$\n\n* Covariance matrix\n\n$$\n  K_{\\mathbf{X}}=\\mathrm{E}[(\\mathbf{X}-\\mathrm{E}[\\mathbf{X}])(\\mathbf{X}-\\mathrm{E}[\\mathbf{X}])^{\\dagger}]\n$$\n\n* Uncorrelated if $K_{\\mathbf{X}}$ diagonal\n* Eigen decomposition $K_{\\mathbf{X}}=V\\Sigma V^{\\dagger}$, where\n\n    * $V$ is a unitary matrix, i.e., $VV^{\\dagger}=I$, of eigenvectors\n    * $\\Sigma$ is a diagonal matrix of non-negative eigenvalues\n\n* Complex-valued random variable can be treated as a 2D real-valued random vector\n\n**EXERCISE:** Given a random vector $\\mathbf{X}$ and matrix $A$, let $\\mathbf{Y} = A\\mathbf{X}$. Verify that\n\n$$\n  \\boldsymbol{\\mu}_{\\mathbf{Y}}=A \\boldsymbol{\\mu}_{\\mathbf{X}}\n$$\n\nand\n\n$$\n  K_{\\mathbf{Y}} = A K_{\\mathbf{X}} A^\\dagger\n$$\n\n## Gaussian Random Variables and Vectors\n\n### Gaussian Random Variable\n\nA Gaussian random variable $X$ has PDF\n\n$$\n  f_{X}(x)=N(x;\\mu,\\sigma^{2}):=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{-(x-\\mu)^{2}/2\\sigma^{2}}\n$$\n\nNotes\n* \"Bell curve\" centered at $\\mu$\n* $\\sigma^{2}$ specifies the \"spread\" of the curve\n* CDF not available in closed form, but either tabulated or computed by numeric integration\n* $N(z;0,1)$ is called the *standard normal* distribution, and for any Gaussian random variable $X$, $Z=(X-\\mu)/\\sigma$ has the standard normal distribution\n\nThe function special function\n$$\n  Q(x):=\\frac{1}{\\sqrt{2\\pi}}\\int_{x}^{+\\infty}e^{-z^{2}/2}dz\n$$\n\nis often used in communications. Note that:\n\n* $Q(0)=1/2$\n* $Q(-x)=1-Q(x)$ for $x < 0$\n\nThe Python code generates what is called a *histogram* used to estimate the PDF of samples from a Gaussian distribution, and compares the historgram to the actual PDF.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nmu, sigma = 5, 2 # mean and standard deviation\ns = np.random.normal(mu, sigma, 10000)\ncount, bins, ignored = plt.hist(s, 50, density=True,label='Histogram')\nplt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n         np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n         linewidth=2, color='r',label='True PDF')\nplt.legend()\nplt.xlabel('$x$')\nplt.ylabel('$f_X(x)$')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec23-AWGN_files/figure-html/cell-2-output-1.png){width=607 height=422}\n:::\n:::\n\n\n#### Jointly Gaussian Random Vectors\n\nA random vector $\\mathbf{X} = [\\begin{array}{cccc}\nX_{1} & X_{2} & \\cdots & X_{n}\\end{array}]^{\\intercal}$ is said to be *jointly Gaussian* if its joint distribution is of the form\n\n$$\n  f_{\\mathbf{X}}(\\mathbf{x})=\\frac{1}{\\sqrt{(2\\pi)^{n}|K_{\\mathbf{X}}|}}e^{-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu}_{\\mathbf{X}})K_{\\mathbf{X}}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_{\\mathbf{X}})^{\\dagger}}\n$$\n\nNotes\n* The jointly Gaussian distribution is completely specified by the mean vector $\\boldsymbol{\\mu}_{\\mathbf{X}}$ and the covariance matrix $K_{\\mathbf{X}}$ of the random vector\n* Linear transformations of jointly Gaussian random variables are jointly Gaussian\n* Equi-probability density contours of jointly Gaussian variables are ellipses. The ellipses are centered at the mean vector $\\boldsymbol{\\mu}_{\\mathbf{X}}$, and if we consider the eigen decomposition $K_{\\mathbf{X}}=V\\Sigma V^{\\dagger}$, the principle axes of the ellipses are aligned to the eigenvectors in $V$, and the relative spread of the distribution along each major axis is controlled by the corresponding eignvalue in $\\Sigma$.\n* Uncorrelated jointly Gaussian random variables are mutually independent. In particular, if\n\n$$\n  K_{\\mathbf{X}} = \\mathrm{diag}(\\sigma_1^2,\\sigma_2^2,\\ldots,\\sigma_n^2)\n$$\n\nthen\n\n$$\n  f_{\\mathbf{X}}(\\mathbf{x})=\\prod_{i=1}^{n} N(x_i;\\mu_i,\\sigma_i^{2}) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma_i^{2}}}e^{-(x_i-\\mu_i)^{2}/2\\sigma_i^{2}}\n$$\n\nThe Python code below can be used to experiment with the 2D jointly Gaussian distribution, and generates what is called a *scatter plot* of samples from the distribution.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Mean vector\nMu_X = [1, 2]\n\n# Eigenvectors in terms of a 2D Givens rotation\ntheta = 2*np.pi/8\nV = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])\n# Eigenvalues\nSigma = np.array([[3,0],[0,1]])\n\nK_X = np.matmul(np.matmul(V,Sigma),np.transpose(V))\n\nx, y = np.random.multivariate_normal(Mu_X, K_X, 5000).T\n\nplt.plot(x, y, '.')\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$y$\")\nplt.axis('square')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec23-AWGN_files/figure-html/cell-3-output-1.png){width=429 height=422}\n:::\n:::\n\n\n## Simulation of AWGN Processes\n\nIn the previous two lectures, we summarized a few important results about the effects of thermal noise in our receiver. They are:\n\n1. Thermal noise in all the resistors in the receiver can be modeled as stationary, white Gaussian noise. These noise sources can further be modeled as being independent of each other.\n\n2. The noise power at the output of the receiver can be determined form the noise power at its input, its overall gain, and its noise figure.\n\n3. Assuming the circuits behave linearly on the noise signals, the output noise should be well-modeled as white Gaussian as well.\n\n4. In the equivalent circuit model, the signal and output noise sources superimpose on the load.\n\nSuppose we want to simulate a bandlimited thermal and circuit noise source for the output of a receiver. We can generate a large number of independent and identically distributed (IID) Gaussian random samples that are zero mean with the appropriate variance, and apply bandlimited interpolation to produce the corresponding continuous-time random voltage signal.\n\nIn particular, let $W[n] \\sim N(0,\\sigma_w^2)$, $n=0,1,2,\\ldots,N-1$, and then let\n\n$$\n  W(t) = \\sum_{n=0}^{N-1} W[n]\\ \\mathrm{sinc}\\left(\\frac{t-nT_s}{T_s} \\right)\n$$\n\nwhere $T_s=1/(2B)$.\n\nAs $N$ becomes large, the resulting random waveform for $t\\in[LT_s,(N-1-L)T_s]$ will be Gaussian and approximately bandlimited, and will be a good model for bandlimited thermal and circuit noise. Here $L$ is a positive integer that eliminates some of the edge effects.\n\nThe last issue that we have to address is the approrpriate choice of the noise variance for the simulated process. If the equivalent noise input to our receive is thermal noise with power spectral density $4kTR_{eq}$, and our receiver has overall gain $G$ and noise figure $\\mathrm{NF}$, then we should set\n\n$$\n  \\sigma_w^2 = \\mathrm{NF}\\cdot G \\cdot (4kTR_{eq}B)\n$$\n\nwhere $R_{eq}$ is the equivalent resistance generating the thermal noise at the receiver input.\n\nThe following Python code interpolates IID Gaussian samples\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom scipy import signal\n\n# Compute the standard deviation of the thermal noise samples\nReq=50\nB=25e6\nT=300\nk=1.38e-23\nG=1000 # 30 dB\nNF=2   #  3 dB\nsigma_w = np.sqrt(NF*G*(4*k*T*Req*B))\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Generate IID zero-mean random Gaussian samples\nN=10000\nwn = np.random.normal(0.0,sigma_w,N)\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Frequencies and oversampling\nfs=100e6     # ADC sampling rate\nTs=1/fs      # ADC sampling period\nM=int(fs/B)  # Oversampling factor for CT approximation\n\n# Sinc interpolation filter, truncated to +/- L periods\nL=20\nn=np.linspace(-L*M,L*M,2*L*M+1)\nh=np.sinc(n/M)\n\n# Plot\nplt.stem(n,h,use_line_collection=True)\nplt.xlabel('$n$')\nplt.ylabel('$\\mathrm{sinc}(n/M)$')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec23-AWGN_files/figure-html/cell-6-output-1.png){width=601 height=422}\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Interpolation\nwt = signal.upfirdn(h,wn,M,1)\nplt.plot(Ts*np.arange(wt.size),wt,'-')\nplt.xlabel('Time (s)')\nplt.ylabel('Noise Voltage $w_{eq}(t)$')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec23-AWGN_files/figure-html/cell-7-output-1.png){width=639 height=422}\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n## Gaussian Histogram\n\ncount, bins, ignored = plt.hist(s, 50, density=True,label='Histogram')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec23-AWGN_files/figure-html/cell-8-output-1.png){width=587 height=404}\n:::\n:::\n\n\nWe expect the noise PSD to be the value below in the passband\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nSwdBm=10*np.log10(NF*G*(4*k*T*Req)*1000)\nprint(SwdBm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-117.80939667551138\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Frequency domain view\nPww, freqs = plt.psd(wt*np.sqrt(1000),512,fs,sides='twosided',label='Bandlimited, Measured')\nplt.plot(freqs,SwdBm*np.ones(freqs.size),'--',label='Wideband, Predicted')\nplt.xlabel('Frequency (MHz)')\nplt.ylabel('Power Spectral Density $S_{w_{eq}}(f)$ (dBm)')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec23-AWGN_files/figure-html/cell-10-output-1.png){width=609 height=422}\n:::\n:::\n\n\n",
    "supporting": [
      "Lec23-AWGN_files"
    ],
    "filters": [],
    "includes": {}
  }
}