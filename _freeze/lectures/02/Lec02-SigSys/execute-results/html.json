{
  "hash": "f82731489bbf5b627266cb0562ff6a9d",
  "result": {
    "markdown": "---\ntitle: 'Lecture 02 - Signals, Systems, and Transforms'\n---\n\n## Summary\n\nIn this lecture, we will review some of the important concepts and terminology, and our notation, from what is commonly called *signals and systems*.\n\nWe focus initially on single-input, single-output, *linear time-invariant (LTI) systems*. The key idea in LTI systems is that their effect on complex exponential signals is particularly simple. This motivates *transforms* between the time domain and frequency domain through we represent general signals as linear combinations of complex exponentials.\n\nWe address these notions in both continuous-time domain and discrete-time domain, and set the stage for connecting the two domains in the next lecture.\n\n## Motivation in Course Context\n\nTwo important components in the modern radio architecture we discussed in the previous lecture were the digital-to-analog converter (DAC) in the transmitter and the analog-to-digital converter (ADC) in the receiver.\n\n**TBD:** Insert block diagrams of DAC and ADC\n\nIn this lecture, we review the background material required to treat these inputs and outputs as continuous-time signals and discrete-time sequences, and we develop the appropriate notions of the frequency domain and the important class of LTI systems. In our next lecture, we will address sampling, interpolation, and quantization aspects of DACs and ADCs.\n\n## Signals and Sequences\nWhen we wire up an electrical circuit, we can use an instrument to measure a voltage or current, either of which typically varies over time.\n\nMathematically, we denote time by the real variable $t \\in \\mathbb{R}$, which we refer to as the *continunous-time axis*, and we denote the voltage or current by the real-valued functions $v(t)$ and $i(t)$, respectively.\n\nMore generally, we can consider any quantity that varies as a function of time as a *signal*, and we generically denote it by $s(t)$. As other examples, we could measure the temperature in a room, or the price of a stock, or ... as functions time.\n\nIf, for whatever reason, we are only able to measure a signal at the discrete time instants $t=nT_s$ for integer $n \\in \\mathbb{Z}$, which we refer to as the *discrete-time axis*, we denote the *sequence* by $s[n]=s(nT_s)$, accordingly. Although the time axis is discrete in the variable $n$, in general $s[n]$ can take real values.\n\nIn this context, we refer to the value $x[n_0]$ as the *sample* of $x(t)$ for $t=n_0 T_s$, $n_0\\in\\mathbb{Z}$. We refer to the spacing between samples in time $T_s$ as the *sampling period*, and we define $f_s=1/T_s$ as the sampling frequency.\n\nFinally, we often consider complex-valued signals and sequences such as\n$$\ns(t) = s_R(t)+j s_I(t)\n$$\n$$\ns[n] = s_R[n]+j s_I[n]\n$$\nwhere $s_R(t)$ and $s_I(t)$ are real-valued signals, $s_R[n]$ and $s_I[n]$ are real-valued sequences, and $j=\\sqrt{-1}$ is the standard notation for the unit imaginary number in the field of electrical engineering.\n\n### Simple Signals\nIn this section, we define and visualize a number of simple signals.\n\n#### Constant Signal\nThe simplest possible signal is the *constant signal* for which $s(t)=A$ for some constant value $A \\in \\mathbb{R}$ and all $t\\in\\mathbb{R}$.\n\nThat is, the constant signal takes the same value for all time.\n\n#### Rising Exponential Signal\nAnother simple signal is the *rising exponential signal*\n$$\nr_{\\tau}(t) :=\n  \\begin{cases}\n  1-e^{-t/\\tau} & t \\ge 0 \\\\\n  0 & t < 0\n  \\end{cases},\n$$ {#eq-ct-rising-exponential}\nwhere $\\tau > 0$ is called the *time constant*.\n\nSince $e^{-t/\\tau}$ decays to $0$ as $t$ becomes large, i.e., $\\lim_{t\\rightarrow\\infty} e^{-t/\\tau} = 0$, we see that $r_{\\tau}(t)$ approaches $1$ as $t$ becomes large, i.e., $\\lim_{t\\rightarrow\\infty} r_{\\tau}(t)=1$.\n\nHow fast $r_{\\tau}(t)$ approaches $1$ depends upon the time constant $\\tau$: larger values of $\\tau$ cause $r_{\\tau}(t)$ to approach $1$ more slowly, and smaller values of $\\tau$ cause $r_{\\tau}(t)$ to approach $1$ more rapidly.\n\nThis is illustrated in the simple numerical calculation and plot below.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pylab as plt\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ntau1 = 1\ntau2 = 4\nt=np.linspace(0,20,40)\nr1 = 1-np.exp(-t/tau1)\nr2 = 1-np.exp(-t/tau2)\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nlabel1 = \"$\\\\tau=\"+str(tau1)+\"$\"\nlabel2 = \"$\\\\tau=\"+str(tau2)+\"$\"\nplt.plot(t,r1,'s-',label=label1)\nplt.plot(t,r2,'s-',label=label2)\nplt.xlabel('$t$')\nplt.ylabel('$r_{\\\\tau}(t)$')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec02-SigSys_files/figure-html/cell-4-output-1.png){width=590 height=422}\n:::\n:::\n\n\n**EXERCISE:**\nVerify that, to achieve $r_{\\tau}(t) \\ge 0.99$, we require $t \\ge -\\ln(0.01)\\cdot \\tau \\approx 4.6 \\cdot \\tau$.\n\nThus, a good rule of thumb is that a rising exponential signal essentially converges to its limit after five time constants. The duration $5\\tau$ is sometimes called the *rise time* of the rising exponential signal.\n\n#### Unit Step Signal\nAnother simple signal is the *unit step signal*\n$$\nu(t) :=\n  \\begin{cases}\n  1 & t > 0 \\\\\n  0 & t \\le 0\n  \\end{cases}.\n$$ {#eq-ct-unit-step}\nThat is, the unit step signal \"turns on\" after time $t=0$ after being \"off\" for $t \\le 0$.\n\nNotice that the unit step can be viewed as a pointwise limit of the rising exponential signal as $\\tau$ approaches $0$, i.e.,\n$u(t) = \\lim_{\\tau\\rightarrow 0} r_{\\tau}(t)$ for all $t\\in\\mathbb{R}$.\n\nOn one hand, the mathematical expression for $u(t)$ is simpler than that of the rising exponential signal, so $u(t)$ can be a convenient approximation to the rising exponential signal for small $\\tau$.\n\nOn the other hand, $u(t)$ is discontinuous at $t=0$, whereas the rising exponential signal is continuous for all $t$.\n\n**EXERCISE:**\nVerify that\n$$\nu(t-\\tau) = \n  \\begin{cases}\n  1 & t > \\tau \\\\\n  0 & t \\le \\tau\n  \\end{cases}.\n$$\nIn words, the delayed unit step signal $u(t-\\tau)$ is off for $t \\le \\tau$ and on for $t > \\tau$.\n\n#### Rectangular Signal\nAnother simple signal is the *rectangular signal*\n$$\n\\mathrm{rect}(t) := u\\left(t+\\frac{1}{2}\\right) - u\\left(t-\\frac{1}{2}\\right).\n$$ {#eq-ct-rectangular}\n\n**EXERCISE:**\nVerify that\n$$\n\\mathrm{rect}(t) =\n  \\begin{cases}\n  1 & |t| < \\frac{1}{2} \\\\\n  0 & |t| \\ge \\frac{1}{2}\n  \\end{cases}.\n$$\nIn words, the rectangular signal $\\mathrm{rect}(t)$ is off for $t \\le -1/2$, turns on for $-1/2 < t < +1/2$, and then turns off for $t > +1/2$.\n\n**EXERCISE:**\nDetermine a simple expression for $\\mathrm{rect}(t/T)$ for $T > 0$.\n\n#### Dirac Delta Signal\nAnother signal that is actually defined in terms of a pointwise limit of functions is the *Dirac delta signal*\n$$\n\\delta(t) := \\lim_{\\epsilon\\rightarrow 0} \\delta_{\\epsilon}(t), \\quad t \\in \\mathbb{R},\n$$ {#eq-ct-dirac-delta}\nwhere $\\delta_{\\epsilon}(t)$ is a set of functions parameterized by $\\epsilon > 0$ satisfying\n$$\n\\int_{-\\infty}^{+\\infty} \\delta_{\\epsilon}(t) dt = 1, \\quad \\epsilon > 0,\n$$ {#eq-ct-dirac-unit-area}\nand\n$$\n\\lim_{\\epsilon\\rightarrow 0} \\delta_{\\epsilon}(t) = \n  \\begin{cases}\n  +\\infty & t = 0 \\\\\n  0 & t \\neq 0\n  \\end{cases}.\n$$ {#eq-ct-dirac-origin-divergence}\n\nThe simplest such set of functions is given by\n$$\n\\delta_{\\epsilon}(t)=\\frac{1}{\\epsilon}\\mathrm{rect}\\left(\\frac{t}{\\epsilon}\\right) =\n  \\begin{cases}\n  \\frac{1}{\\epsilon} & |t| < \\frac{\\epsilon}{2} \\\\\n  0 & |t| \\ge \\frac{\\epsilon}{2}\n  \\end{cases}.\n$$\nThat is, the $\\delta_{\\epsilon}(t)$ functions are rectangular with width $\\epsilon$ and height $\\frac{1}{\\epsilon}$, so that they become narrower and taller as $\\epsilon$ becomes smaller.\n\nAn important property satisfied by the Dirac delta signal is the *sifting property*, which states that for a signal $s(t)$, $t \\in\\mathbb{R}$,\nand for any $\\tau\\in\\mathbb{R}$,\n$$\n\\int_{-\\infty}^{+\\infty} s(t) \\delta(t-\\tau) dt = s(\\tau).\n$$ {#eq-ct-dirac-sifting-property}\nIn words, a Diract delta signal delayed by $\\tau$ \"sifts\" out the value of the signal $s(t)$ for $t=\\tau$ under the integral.\n\n#### Sinusoidal Signals\nAnother very important class of signals are *sinusoidal signals*, such as $\\cos(2\\pi f_0 t)$ and $\\sin(2\\pi f_0 t)$ for all $t \\in \\mathbb{R}$ and a given $f_0 > 0$. If we define $T_0 = 1/f_0$, we observe the following interesting property:\n$$\n  \\cos(2\\pi f_0 (t + k T_0)) = \\cos(2\\pi f_0 t + k2\\pi)=\\cos(2\\pi f_0 t), \\quad k\\in\\mathbb{Z}.\n$$\n\nIn words, the sinusoidal signal $\\cos(2\\pi f_0 t)$ is *periodic* with fundamental period $T_0 = 1/f_0$.\n\nThe parameter $f_0$ is called the *frequency* of the sinusoid, and represents the number of periods or *cycles* of the sinusoid in one second. The units of frequency are *Hertz*.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nf_0 = 10\nT_0 = 1/f_0\nt = np.linspace(-2*T_0,2*T_0,4*20)\nc = np.cos(2*np.pi*f_0*t)\ns = np.sin(2*np.pi*f_0*t)\n\nplt.plot(t,c,'s-',label='cos')\nplt.plot(t,s,'s-',label='sin')\nplt.xlabel('t')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec02-SigSys_files/figure-html/cell-5-output-1.png){width=590 height=422}\n:::\n:::\n\n\n**EXERCISE:**\nShow that $\\cos(2\\pi f_0 t + \\pi/2)=\\sin(2\\pi f_0 t)$, i.e., the $\\cos$ \"leads\" the $\\sin$, or the $\\sin$ \"lags\" the $\\cos$, by $\\pi/2$ radians or $90^{\\circ}$.\n\n#### Continuous-Time Complex Exponential Signals\n\nThe last class of simple signals we will mention are *complex exponential signals* of the form $e^{j 2\\pi f_0 t}$ for all $t \\in \\mathbb{R}$ and a given $f_0 \\in \\mathbb{R}$, where $j=\\sqrt{-1}$.\n\nUsing Euler's relation, we have\n$$\ne^{j 2\\pi f_0 t} = \\cos(2\\pi f_0 t) + j\\sin(2 \\pi f_0 t).\n$$ {#eq-eulers-relation}\nThat is, the complex exponential signal has the $\\cos$ and $\\sin$ signals of a given frequency as its real and imaginary parts, respectively.\n\nThe following plot shows the $\\cos$ and $\\sin$ signals from the previous example in the complex plane (XY mode). The complex exponential cycles around the unit circle $f_0$ times per second. Specifically, for this example with $f_0 > 0$ and comparing to the previous figure, the complex exponential starts at the point $(1,0)$ and rotates counter clockwise through the points $(0,1)$, $(-1,0)$, and $(0,-1)$. For $f_0 < 0$, the complex exponential cycles clockwise around the unit circle $-f_0$ times per second.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nplt.plot(c,s,'s-')\nplt.xlabel('Real Part')\nplt.ylabel('Image Part')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Lec02-SigSys_files/figure-html/cell-6-output-1.png){width=608 height=422}\n:::\n:::\n\n\n**EXERCISE:**\nVerify using Euler's relation that\n$$\n\\cos(2\\pi f_0 t) = \\frac{1}{2} \\left[e^{j 2\\pi f_0 t} +  e^{-j 2\\pi f_0 t}\\right]\n$$ {#eq-cosine-euler}\nand\n$$\n\\sin(2\\pi f_0 t) = \\frac{1}{2j} \\left[e^{j 2\\pi f_0 t} -  e^{-j 2\\pi f_0 t}\\right].\n$$ {#eq-sine-euler}\n\n**EXERCISE:**\nVerify using Euler's relation the following trigonometric identities\n$$\n\\cos(2\\pi f_1 t) \\cos(2\\pi f_2 t) = \\frac{1}{2}[\\cos(2\\pi (f_1-f_2) t)+\\cos(2\\pi (f_1+f_2) t)]\n$$ {#eq-cosine-product-trig-identity}\n$$\n\\sin(2\\pi f_1 t) \\sin(2\\pi f_2 t) = \\frac{1}{2}[\\cos(2\\pi (f_1-f_2) t)-\\cos(2\\pi (f_1+f_2) t)]\n$$ {#eq-sine-product-trig-identity}\n$$\n\\cos(2\\pi f_1 t) \\sin(2\\pi f_2 t) = \\frac{1}{2}[\\sin(2\\pi (f_1+f_2) t)-\\sin(2\\pi (f_1-f_2) t)]\n$$ {#eq-cosine-sine-trig-identity}\n\n#### Discrete-Time Complex Exponential Sequences\n\nWe can think of a discrete-time complex exponential sequence as samples of a continuous-time complex exponential signal, but some subtleties arise.\n\nConsider $x(t)=e^{j2\\pi f t}$ for a specific frequency $f \\in\\mathbb{R}$. Let $x[n]$ denote samples of this signal with sampling period $T_s$ (sampling frequency $f_s$), i.e., $x[n]=x(n T_s)$.\n\nThen\n$$\nx[n] = \\left.e^{j2\\pi f t}\\right|_{t=nT_s}=e^{j2\\pi(f/f_s) n}\n$$\nThe ratio $f / f_s$ is called the *normalized frequency* of the discrete-time complex exponential, with units of *cycles per sample*.\n\nIf $f_s / f$ is an integer, the DT complex exponential is periodic, i.e., $x[n+kN_0]=x[n]$ for all $n\\in\\mathbb{Z}$. In this case, the period $N_0 = f_s/f$, the inverse of the normalized frequency.\n\nNow consider $y_k(t)=e^{j2\\pi (f + k f_s) t}$, for a specific frequency $f \\in\\mathbb{R}$ and a specific integer $k\\in\\mathbb{Z}$. In words, the frequency of $y_k(t)$ is the frequency of $x(t)$ plus an integer multiple $k$ of the sampling frequency $f_s$.\n\nThe corresponding discrete-time complex exponential is\n$$\ny_k[n] = \\left. y_k(t) \\right|_{t=nT_s} = e^{j2\\pi((f+k f_s)/f_s) n}=e^{j2\\pi k} e^{j2\\pi (f/f_s) n}=e^{j2\\pi (f/f_s) n}=x[n]\n$$\nsince $e^{j2\\pi k}=1$, $k\\in\\mathbb{Z}$.\n\nIn words, the discrete-time samples corresponding to all continuous-time frequencies $f + k f_s$ are exactly the same. The continuous-time frequency $f+k f_s$ is said to *alias* to the frequency $f$, or the normalize frequency $f/f_s$, for **all** $k\\in\\mathbb{Z}$.\n\nAnother way to view this effect is that, for discrete-time sequences, the normalized frequency axis $(f/f_s)$ is periodic with fundamental period $1$.\n\nWe therefore focus on discrete-time normalized frequencies on the interval $[-1/2,+1/2]$ as a convention, and we use the variable $u$ to denote normalized frequencies.\n\n## Signal Energy and Power\n\nWe will often deal with finite-energy or finite-power signals.\n\nThe *energy* of a signal $s(t)$ is defined as\n$$\nE_s = \\lim_{T\\rightarrow\\infty} \\int_{-T/2}^{+T/2} |s(t)|^2 dt\n$$ {#eq-ct-energy}\nwhen the limit exists. The absolute value of the integrand is important for dealing with complex-valued signals.\n\nThe *(average) power* of a signal $s(t)$ is defined as\n$$\nP_s = \\lim_{T\\rightarrow\\infty} \\frac{1}{T}\\int_{-T/2}^{+T/2} |s(t)|^2 dt\n$$ {#eq-ct-power}\nwhen the limit exists.\n\n**EXERCISE:** Verify that the energy and average power of the rectangular signal $\\mathrm{rect}(t/T)$ are $E=T$ and $P=0$, respectively.\n\n**EXERCISE:** Verify that the energy and average power of the complex exponential signal $e^{j2\\pi f_0 t}$ are $\\infty$ and $1$, respectively.\n\nSimilarly, the energy and (average) power of a sequence $s[n]$ are defined as\n$$\nE_s = \\lim_{N\\rightarrow\\infty} \\sum_{-N}^{+N} |s[n]|^2\n$$ {#eq-dt-energy}\nand\n$$\nP_s = \\lim_{N\\rightarrow\\infty} \\frac{1}{2N+1} \\sum_{-N}^{+N} |s[n]|^2\n$$ {#eq-dt-power}\nwhen the limits exist, respectively.\n\n## Correlation\n\nFor two signals $x(t)$ and $y(t)$, we define the *correlation* as\n$$\n<x(t),y(t)>:=\\int_{-\\infty}^{+\\infty}x(t)y^*(t) dt\n$$ {#eq-ct-correlation}\n\nFor two sequences $x[n]$ and $y[n]$, we define the *correlation* as\n$$\n< x[n], y[n]>:=\\sum_{-\\infty}^{+\\infty} x[n] y^*[n]\n$$ {#eq-dt-correlation}\n\nTwo signals (sequences) are said to be *orthogonal* if there correlation is zero.\n\n**EXERCISE:** Determine the correlation of $\\mathrm{rect}(t/T)$ and $\\mathrm{rect}((t-\\tau)/T)$, $t\\in\\mathbb{R}$, for all values of $\\tau,T\\in\\mathbb{R}$. For which values of $\\tau$, if any, are the two signals orthogonal?\n\n**EXERCISE:** Determine the correlation of the signals $e^{j2\\pi f_1 t}$ and $e^{j2\\pi f_2 t}$, $t\\in\\mathbb{R}$, for all values of $f_1,f_2\\in\\mathbb{R}$. For which values of $f_1,f_2$, if any, are the signals orthogonal?\n\n**EXERCISE:** Determine the correlaton of the sequences $e^{j2\\pi u_1 n}$ and $e^{j2\\pi u_2 n}$, $n\\in\\mathbb{Z}$, for all values of $u_1,u_2\\in[-1/2,1/2]$. For which values of $u_1,u_2$, if any, are the sequences orthongonal?\n\n**TBD: Be careful with aliasing effects!**\n\n## Systems\n\nA *system* models the processing of input signal(s) or sequence(s) into output signal(s) or sequence(s). For starters, we will explore systems with a single input and a single output. Systems that process continuous-time signals are called *continuous-time systems*, and systems that process discrete-time sequences are called *discrete-time systems*.\n\nFor simplicity at this point, we denote a system by $\\mathcal{H}$ and its response to input $x(t)$ by $\\mathcal{H}\\{x(t)\\}$.\n\n**TBD: Insert block diagram of system with input and output x -> H -> y**\n\n### Simple Systems\n\n#### Memoryless Operation\n\n**TBD**\n\n#### Delay / Advance\n\n**TBD**\n\n#### Time Limiter\n\n**TBD**\n\n### Linear Time-Invariant Systems\n\nLinearity and time-invariance are two very useful system properties that are satisfied by many systems. Systems that satisfy both properties are called *linear, time-invariant (LTI) systems*.\n\n#### Definitions\n\nA system $\\mathcal{H}$ is *linear* if it satisfies two properties:\n* **Scaling:** If  $y(t)=\\mathcal{H}\\{x(t)\\}$, then input $\\mathcal{H}\\{a x(t)\\}=a y(t)$ for all inputs $x(t)$ and all constaints $a\\in\\mathbb{C}$.\n* **Superposition:** If $y_1(t)=\\mathcal{H}\\{x_1(t)\\}$ and $y_2(t)=\\mathcal{H}\\{x_2(t)\\}$, then $\\mathcal{H}\\{a x_1(t) + b x_2(t)\\}=a y_1(t) + b y_2(t)$, for all inputs $x_1(t)$ and $x_2(t)$ and all constants $a,b\\in\\mathbb{C}$.\n\nA system is *time-invariant* if, for $y(t)=\\mathcal{H}\\{x(t)\\}$, $\\mathcal{H}\\{x(t-\\tau)\\}=y(t-\\tau)$ for all inputs $x(t)$ and all constants $\\tau\\in\\mathbb{R}$.\n\nIn other words, delaying an input produces the same delay in the corresponding output.\n\n#### Convolution Defines the LTI Input-Output Relationship\n\nThe input-ouput relationship for an LTI system can be specified in general from $h(t)=\\mathcal{H}\\{\\delta(t)\\}$, which is called the *impulse response* of the system.\n\nSpecifically we can determine $y(t)=\\mathcal{H}\\{x(t)\\}$ through the *convolution integral*\n$$\ny(t) = \\int_{-\\infty}^{+\\infty} x(\\tau)h(t-\\tau) d\\tau =: x(t) * h(t)\n$$ {#eq-ct-convolution-integral}\nTo see this, we rewrite the input as\n$$\nx(t) = \\int_{-\\infty}^{+\\infty} x(\\tau) \\delta(t-\\tau) d\\tau\n$$\nand apply the LTI properties of the system.\n\nNote that he we are expressing the input as a superposition of many, simpler signals for which the input-output relationship is simple.\n\nAn equivalent relationship is\n$$\ny(t) = \\int_{-\\infty}^{+\\infty} x(t-\\tau)h(\\tau) d\\tau\n$$\n\n#### Complex Exponentials are Eigenfunctions of LTI Systems\n\nWhen we apply a complex exponential as the input to an LTI system, something very interesting and useful happens.\n\nMathematically, if $h(t)$ is the impulse response of the LTI system $\\mathcal{H}$, applying the convolution intergral to the input $e^{j2\\pi f_0 t}$ yields\n$$\n\\int_{-\\infty}^{+\\infty} e^{j2\\pi f_0 (t-\\tau)} h(\\tau) d\\tau = \\int_{-\\infty}^{+\\infty} e^{j2\\pi f_0 t} e^{-j2\\pi f_0 \\tau} h(\\tau) d\\tau = e^{j2\\pi f_0 t} \\left( \\int_{-\\infty}^{+\\infty} h(\\tau) e^{-2\\pi f_0 \\tau} d\\tau\\right)\n$$\n\nIn words, if the input to an LTI system is any complex exponential with frequency $f_0$, the output is a complex exponential with the __exact same frequency__.\n\nFor this reason, we call complex exponentials the *eigenfunctions* of LTI systems.\n\nThe  effect of the LTI system on a complex exponential of frequency $f_0$ is multiplication by the complex-valued scalar\n$$\nH(f_0):=\\int_{-\\infty}^{+\\infty} h(\\tau) e^{-j2\\pi f_0 \\tau} d\\tau\n$$ {#eq-ct-frequency-response}\nAcross all frequencies $f \\in\\mathbb{R}$, which we refer to as the *frequency axis*, the system may have a different value of $H(f)$, which we refer to as the *frequency response*.\n\n**EXERCISE:** Argue that, if\n\n$$\nx(t)=\\sum_{k=1}^{K} a_k e^{j2\\pi f_k t}\n$$\nis input to an LTI system with frequency response $H(f)$, then the corresponding output is\n$$\ny(t)=\\sum_{k=1}^{K} H(f_k) a_k e^{j2\\pi f_k t}\n$$\n\nThe above exercise illustrates that convolution for LTI systems is particularly easy to work with if the input can be written as a sum of complex exponentials. This motivates us to represent as many signals this way as we can!\n\n#### Discrete-Time LTI Systems\n\nVery similar ideas apply to discrete-time systems as well.\n\nThe input-ouput relationship for an DT LTI system can be specified in general from $h[n]=\\mathcal{H}\\{\\delta[n]\\}$, which is called the *impulse response* of the system.\n\nSpecifically we can determine $y[n]=\\mathcal{H}\\{x[n]\\}$ through the *convolution sum*\n$$\ny[n] = \\sum_{k=-\\infty}^{+\\infty} x[k]h[n-k] =: x[n] * h[n]\n$$ {#eq-dt-convolution-sum}\n\nTo see this, we rewrite the input as\n$$\nx[n] = \\sum_{k=-\\infty}^{+\\infty} x[k] \\delta[n-k]\n$$\nand apply the LTI properties of the system.\n\nNote that he we are expressing the input as a superposition of many, simpler signals for which the input-output relationship is simple.\n\nAn equivalent relationship is\n$$\ny[n] = \\sum_{k=-\\infty}^{+\\infty} x[n-k]h[k]\n$$\n\nMathematically, if $h[n]$ is the impulse response of the DT LTI system $\\mathcal{H}$, applying the convolution intergral to the input $e^{j2\\pi u_0 n}$ yields\n$$\n\\sum_{k=-\\infty}^{+\\infty} e^{j2\\pi u_0 (n-k)} h[k] = \\sum_{k=-\\infty}^{+\\infty} e^{j2\\pi u_0 n} e^{-j2\\pi u_0 k} h[k] = e^{j2\\pi u_0 n} \\left( \\sum_{k=-\\infty}^{+\\infty} h[k] e^{-j2\\pi u_0 k} \\right)\n$$\n\nIn words, if the input to an DT LTI system is any complex exponential with normalized frequency $u_0$, the output is a complex exponential with the __exact same frequency__.\n\nFor this reason, we call DT complex exponentials the *eigenfunctions* of DT LTI systems.\n\nThe  effect of the DT LTI system on a complex exponential of normalized frequency $u_0$ is multiplication by the complex-valued scalar\n$$\nH(e^{j2\\pi u_0}):=\\sum_{k=-\\infty}^{+\\infty} h[k] e^{-j2\\pi u_0 k}\n$$ {#eq-dt-frequency-response}\nAcross all frequencies $u \\in\\mathbb{R}$, which we refer to as the *discrete-time frequency axis*, the system may have a different value of $H(e^{j2\\pi u})$, which we refer to as the *discrete-time frequency response*.\n\n**EXERCISE:** Argue that, if\n\n$$\nx[n]=\\sum_{k=1}^{K} a_k e^{j2\\pi u_k n}\n$$\nis input to an DT LTI system with frequency response $H(e^{j2\\pi u})$, then the corresponding output is\n$$\ny[n]=\\sum_{k=1}^{K} H(e^{j2\\pi u_k}) a_k e^{j2\\pi u_k n}\n$$\n\n## Representation of Periodic Signals by Sums of Exponentials\n\nThis section focuses on periodic CT signals that satisfy $x(t+T_0)=x(t)$, $t\\in\\mathbb{R}$, for some $T_0>0$ and periodic DT sequences that satisfy $x[n+n_0]=x[n]$, $n\\in\\mathbb{Z}$ for some integer $N_0 >0$.\n\n### Continuous-Time\n\nIf $x(t)$ is a periodic signal with fundamental period $T_0 > 0$, then we can represent it by the infinite sum of complex exponentials\n$$\nx(t) = \\mathrm{l.i.m.}_{k\\rightarrow\\infty} \\sum_{-k}^{k} a_k e^{j2\\pi k t / T_0}\n$$ {#eq-ct-fourier-series-inverse}\nand we may easily determine the coefficients $a_k$, $k\\in\\mathbb{Z}$ via a correlation over any interval of length $T_0$, for example,\n$$\na_k = \\left< x(t) , \\frac{1}{T_0} e^{j2\\pi k t / T_0} \\right> = \\frac{1}{T_0} \\int_{-T_0/2}^{T_0/2} x(t) e^{-j2\\pi k t / T_0} dt\n$$ {#eq-ct-fourier-series}\nThis representation is called the *continuous-time Fourier series*.\n\nRemarks\n\n* The Fourier series represents a periodic CT signal $x(t)$, $t\\in\\mathbb{R}$ by the DT sequence $a_k$, $k\\in\\mathbb{Z}$.\n* The complex exponentials are *harmonically related* in the sense that the frequencies are integer multiples of $f_0 = 1/T_0$, which we call the *fundamental frequency*.\n\n* For an LTI system with frequency response $H(f)$, the output corresponding to the periodic input $x(t)$ will be\n$$\n\\mathrm{l.i.m.}_{k\\rightarrow\\infty} \\sum_{-k}^{k} H(kt/T_0) a_k e^{j2\\pi k t / T_0}\n$$\nthat is, we apply the system to each component frequency, exploit the eigenfunction property of complex exponentials for LTI systems, and sum the results using linearity.\n\n* The limiting behavior of the summation is in the sense of *mean-square convergence*, and is fairly technical. In particular, if we consider the finite summation\n$$\nx_K(t) = \\sum_{-K}^{K} a_k e^{j2\\pi k t / T_0}\n$$\nthen $x(t)=\\mathrm{l.i.m.}_{K\\rightarrow\\infty} x_K(t)$ means that\n$$\n\\lim_{K\\rightarrow\\infty} \\int_{-T_0/2}^{T_0/2} |x(t) - x_K(t)|^2 dt = 0\n$$\n\nIn words, the integral of the squared difference between the two signals approaches zero, rather than the difference betweeen the signals themselves going to zero for all $t\\in\\mathbb{R}$.\n\n**TBD: Periodic square wave and Gibbs phenomenon, in Python plot**\n\n#### Discrete-Time\n\nIf $x[n]$ is a periodic signal with integer fundamental period $N_0 > 0$, then we can represent it by the finite sum of complex exponentials\n$$\nx[n] =  \\sum_{0}^{N_0-1} a_k e^{j2\\pi (k/N_0) n}\n$$ {#eq-dt-fourier-series-inverse}\nand we may easily determine the coefficients $a_k$, $k=0,1,\\ldots,N_0-1$ via a correlation over any interval of $N_0$ samples, for example,\n$$\na_k = \\left< x[n] , \\frac{1}{N_0} e^{j2\\pi (k/N_0) n} \\right> = \\frac{1}{N_0} \\sum_{n=0}^{N_0-1} x[n] e^{-j2\\pi (k/N_0) n}\n$$ {#eq-dt-fourier-series}\nThis representation is called the *discrete-time Fourier series*.\n\nRemarks\n\n* The Fourier series represents a periodic DT sequence $x[n]$ by a finite set of coefficients $a_k$,$k=0,1,...,N_0-1$.\n* The complex exponentials are harmonically related in the sense that their normalized frequences are $(k/N_0)$, $k=0,1,\\ldots,N_0-1$, where $1/N_0$ is the fundamental frequency.\n\n* For an LTI system with frequency response $H(e^{j2\\pi u})$, the output corresponding to the periodic input $x[n]$ will be\n$$\n\\sum_{k=0}^{N_0-1} H(e^{j2 \\pi k/N_0}) a_k e^{j2\\pi (k/N_0) n}\n$$\nthat is, we apply the system to each component frequency, exploit the eigenfunction property of complex exponentials for LTI systems, and sum the results using linearity.\n\n* The *Discrete Fourier Transform (DFT)* of a sequence of length $N$ is defined as\n$$\nX[k] = \\sum_{n=0}^{N} x[n] e^{-j\\pi (k/N) n}\n$$ {#eq-dft}\nfor $k=0,1,\\ldots,N-1$. The discrete-time Fourier series coefficients are related to the DFT via the relationship $N a_k = X[k]$, so that the inverse DFT becomes\n$$\nx[n] = \\frac{1}{N} \\sum_{k=0}^{N} X[k] e^{j\\pi (k/N) n}\n$$ {#eq-dft-inverse}\nThis set of relationships are important because there is an efficient algorithm for computing the DFT (and inverse DFT) called the *Fast Fourier Transform (FFT)*, particularly when $N$ is a power of $2$.\n\n## Representation of Aperiodic Signals by Sums of Exponentials\n\nNot all signals are periodic, but we still want to represent them as sums of complex exponentials to build upon the machinery above.\n\n### Continuous-Time\n\nThe signal $x(t)$ can be presented as an integral over a continuum of complex exponential signals over all frequencies via\n$$\nx(t) = \\mathrm{l.i.m.}_{B\\rightarrow\\infty} \\int_{-B/2}^{B/2} X(f) e^{j2\\pi f t} df\n$$ {#eq-ct-inverse-fourier-transform}\nwhere $X(f)$ denotes the *continuous-time Fourier transform* of $x(t)$, assuming the limit exists.\n\nThe CT Fourier transform can be defined in a fairly general sense as\n$$\nX(f) = \\mathrm{l.i.m.}_{T\\rightarrow\\infty} \\int_{-T/2}^{T/2} x(t) e^{-j2\\pi f t} dt\n$$ {#eq-ct-fourier-transform}\nassuming the limit exists.\n\nFor compactness, we denote a CT Fourier transform pair by $x(t) \\leftrightarrow X(f)$.\n\nRemarks\n\n* The CT Fourier transform of a complex exponential $e^{j2\\pi f_0 t}$ is stricly not well defined, unless we generalize to allow Dirac delta functions in the frequency domain. In that case, $e^{j2\\pi f_0 t} \\leftrightarrow \\delta(f - f_0)$. We can obtain this intuition by time-limiting the complex exponential as $e^{j2\\pi f_0 t} \\mathrm{rect}(t/T)$, computing the CT Fourier transform, and then taking the limit as $T\\rightarrow \\infty$.\n\n* Energy and correlation can be computed in the frequency domain. Specifically,\n$$\nE_x = \\int_{-\\infty}^{\\infty} |x(t)|^2 dt = \\int_{-\\infty}^{\\infty} |X(f)|^2 df\n$$ {#eq-ct-parsevals}\n$$\n<x(t),y(t)> = \\int_{-\\infty}^{\\infty} x(t)y^*(t) dt = \\int_{\\infty}^{\\infty} X(f)Y^*(f) df = <X(f),Y(f)>\n$$ {#eq-ct-plancherals}\nThese results are called *Parseval's* and *Plancheral's* relationships, respectively.\n\n* With this definition, convolution in the time domain becomes multiplication in the frequency domain. That is, if the $H(f)$ represents the frequency response of the LTI system $\\mathcal{H}$, i.e., the Fourier transform of the impulse response $h(t)$, then the input-output relationship $y(t)=x(t) * h(t)$ is becomes $Y(f)=H(f)X(f)$.\n\n* There are some extremely sophisticated mathematics with regard to integration and limit operations in order to provide a general notion of the Fourier transform and inverse Fourier transform. The commonly most general definitions relay on Lesbegue integration and mean-square limits, whereas most undergraduates are familiar with Riemann integration and pointwise limits.\n\n### Discrete-Time\n\nThe sequence $x[n]$ can be represented as an integral over a continuum of complex exponential sequences over all normalized frequencies in any interval of length $1$, for example\n$$\nx[n] = \\int_{-1/2}^{1/2} X(e^{j2\\pi u}) e^{j2\\pi u n} du\n$$ {#eq-dt-fourier-transform-inverse}\nwhere $X(e^{j2\\pi u})$ denotes the *discrete-time Fourier transform* of $x[n]$ as a function of the normalized frequency $u$.\n\nThe DT Fourier transform is defined as\n$$\nX(e^{j2\\pi u}) = \\sum_{n=-\\infty}^{\\infty} x[n] e^{-j2\\pi u n}\n$$ {#eq-dt-fourier-transform}\nassuming the limit exists.\n\nFor compactness, we denote a DT Fourier transform pair by $x[n] \\leftrightarrow X(e^{j2\\pi u})$.\n\nRemarks\n\n* Building upon our earlier discussion of discrete-time complex exponentials, we see that the DT Fourier Transform is periodic with period $1$ on the normalized frequency axis. We tend to focus by convention on the interval $u\\in[-1/2,1/2]$, but we should keep in mind this periodicity.\n\n* The DT Fourier transform of a complex exponential $e^{j2\\pi u_0 n}$ is stricly not well defined, unless we generalize to allow Dirac delta functions in the frequency domain. In that case, $e^{j2\\pi u_0 n} \\leftrightarrow \\delta(u - u_0)$. We can obtain this intuition by time-limiting the complex exponential as $e^{j2\\pi u n} \\mathrm{rect}[n/N]$, computing the DT Fourier transform, and then taking the limit as $N\\rightarrow \\infty$.\n\n* Energy and correlation can be computed in the frequency domain. Specifically,\n$$\nE_x = \\sum_{n=-\\infty}^{\\infty} |x[n]|^2 = \\int_{-1/2}^{1/2} |X(e^{j2\\pi u})|^2 du\n$$ {#eq-dt-parsevals}\n\n$$\n<x[n],y[n]> = \\sum_{n=-\\infty}^{\\infty} x[n]y^*[n] = \\int_{-1/2}^{1/2} X(e^{j2\\pi u})Y^*(e^{j2\\pi u}) du = <X(e^{j2\\pi u}),Y(e^{j2\\pi u})>\n$$ {#eq-dt-plancherals}\nThese results are called *Parseval's* and *Plancheral's* relationships, respectively.\n\n* With this definition, convolution in the time domain becomes multiplication in the frequency domain. That is, if the $H(e^{j2\\pi u})$ represents the frequency response of the DT LTI system $\\mathcal{H}$, i.e., the DT Fourier transform of the impulse response $h[n]$, then the input-output relationship $y[n]=x[n] * h[n]$ becomes $Y(e^{j2\\pi u})=H(e^{j2\\pi u})X(e^{j2\\pi u})$.\n\n",
    "supporting": [
      "Lec02-SigSys_files"
    ],
    "filters": [],
    "includes": {}
  }
}